{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# move up one directory for config files\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"dwhcluster.cysyqtwog01l.us-west-2.redshift.amazonaws.com\" to address: Name or service not known\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e28a7c74fca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CLUSTER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DB_PORT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"host={} dbname={} user={} password={} port={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not translate host name \"dwhcluster.cysyqtwog01l.us-west-2.redshift.amazonaws.com\" to address: Name or service not known\n"
     ]
    }
   ],
   "source": [
    "# Load configuration file\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "    \n",
    "host = config['CLUSTER']['DB_ENDPOINT']\n",
    "dbname = config['CLUSTER']['DB_NAME']\n",
    "user = config['CLUSTER']['DB_USER']\n",
    "password = config['CLUSTER']['DB_PASSWORD']\n",
    "port = config['CLUSTER']['DB_PORT']\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(host, dbname, user, password, port))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load configuration variables\n",
    "\n",
    "iam_role = config['IAM_ROLE']['ARN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Staging Table SQL Queries\n",
    "\n",
    "staging_events_copy = (\"\"\"\n",
    "copy event_stage\n",
    "from 's3://udacity-dend/log_data/2018/11/2018'\n",
    "credentials 'aws_iam_role={}'\n",
    "format as json 's3://udacity-dend/log_json_path.json';\n",
    "\"\"\").format(iam_role)\n",
    "\n",
    "\n",
    "\n",
    "staging_songs_copy = (\"\"\"\n",
    "copy event_stage\n",
    "from 's3://udacity-dend/log_data/2018/11/2018'\n",
    "credentials 'aws_iam_role={}'\n",
    "format as json 's3://udacity-dend/log_json_path.json';\n",
    "\"\"\").format(iam_role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Execute Staging Table SQL Queries \n",
    "copy_table_queries = [staging_events_copy, staging_songs_copy]\n",
    "print(\"Loading Staging Tables...\")\n",
    "    for query in copy_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Star Schema Table SQL Queries\n",
    "\n",
    "songplay_table_insert = (\"\"\"\n",
    "INSERT INTO fact_songplay(songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "SELECT\n",
    "    e.userId || st.song_id || e.itemInSession as songplay_id,\n",
    "    CAST(e.ts as bigint) as start_time,\n",
    "    CAST(e.userId as int) as user_id,\n",
    "    e.level as level,\n",
    "    st.song_id,\n",
    "    st.artist_id,\n",
    "    CAST(e.itemInSession as int) as session_id,\n",
    "    e.location as location,\n",
    "    e.userAgent as user_agent\n",
    "FROM (select * from event_stage where page = 'NextSong') as e\n",
    "LEFT JOIN song_stage st\n",
    "    ON (e.artist = st.artist_name OR e.song = st.title)\n",
    "WHERE song_id <> 'None'\n",
    "ORDER BY start_time ASC\n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"\n",
    "INSERT INTO dim_user (user_id, first_name, last_name, gender, level)\n",
    "SELECT DISTINCT\n",
    "    CAST(e.userID as integer) AS user_id,\n",
    "    e.firstName AS first_name,\n",
    "    e.lastName AS last_name,\n",
    "    e.gender AS gender,\n",
    "    e.level AS level\n",
    "FROM event_stage e\n",
    "WHERE e.page = 'NextSong'\n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"\n",
    "INSERT INTO dim_song (song_id, title, artist_id, year, duration)\n",
    "SELECT DISTINCT\n",
    "    s.song_id AS song_id,\n",
    "    s.title AS title,\n",
    "    s.artist_id AS artist_id,\n",
    "    CAST(s.year as integer) AS year,\n",
    "    CAST(s.duration as decimal(8,2)) AS duration\n",
    "FROM song_stage s\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"\n",
    "INSERT INTO dim_artist (artist_id, name, location, latitude, longitude)\n",
    "SELECT DISTINCT\n",
    "    s.artist_id AS artist_id,\n",
    "    s.artist_name AS name,\n",
    "    s.artist_location AS location,\n",
    "    CONVERT(float, s.artist_latitude) AS latitude,\n",
    "    CONVERT(float, s.artist_longitude) AS longitude\n",
    "FROM song_stage s\n",
    "JOIN event_stage e\n",
    "    ON (e.artist = s.artist_name AND e.song = s.title)\n",
    "WHERE e.page = 'NextSong'\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "INSERT INTO dim_time(time_key, start_time, hour, day, week, month, year, weekday)\n",
    "SELECT DISTINCT\n",
    "    CAST(e.ts as bigint) AS time_key,\n",
    "    TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second' as start_time,\n",
    "    EXTRACT(hour from TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') AS hour,\n",
    "    CAST(DATE_PART(day, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second')  as Integer) AS day,\n",
    "    CAST(DATE_PART(week, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS week,\n",
    "    CAST(DATE_PART(month, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS month,\n",
    "    CAST(DATE_PART(year, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') as Integer) AS year,\n",
    "    CASE\n",
    "        WHEN(\n",
    "                DATE_PART(dayofweek, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') = 0.0\n",
    "                OR\n",
    "                DATE_PART(dayofweek, TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second') = 6.0\n",
    "            )\n",
    "        THEN 'no'\n",
    "        ELSE 'yes'\n",
    "        END\n",
    "        AS weekday\n",
    "FROM event_stage e\n",
    "WHERE e.page = 'NextSong'\n",
    "ORDER BY time_key ASC;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Execute Star Schema Table SQL Queries\n",
    "\n",
    "insert_table_queries = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]\n",
    "for query in insert_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
